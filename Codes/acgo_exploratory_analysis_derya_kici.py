# -*- coding: utf-8 -*-
"""ACGO_Exploratory_Analysis_Derya_Kici.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VmFblb7qJqrBbc6DdnBgvKewMf5Mrqr7

# Alcohol and Gaming Commission of Ontario

Senior Data Scientist Technical Assessment

Derya Kici, June 1, 2023

Develop a predictive model using the given dataset on Chicago restaurant inspections. The aim is to identify establishments at a higher risk of violations
"""

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno
import sklearn
import imblearn

from google.colab import drive
drive.mount("/content/gdrive", force_remount=True)

"""# Load Data"""

# data = pd.read_csv("C:\\Users\\derya\\Desktop\\AGCO Pre-Interview Assessment\\data\\Food Inspections and Violations.csv")
data = pd.read_csv("/content/gdrive/MyDrive/AGCO Pre-Interview Assessment/data/Food Inspections and Violations.csv")
data.head()

data.shape

# Check the missing values
msno.matrix(data)

data.isnull().sum()

data["Results"].unique()

data = data.dropna()

data = data.dropna(subset = ['Violations'])

msno.matrix(data)

data.isnull().sum()

"""The highest number of missing values is in Violations feature. 
The second highest is Facility Type.
This is an important feature in my classification model. 22% of the data is missing When we remove the missing values, we still have over 100K data

"""

data.info()

data.nunique()

data[data.duplicated()]
#There is no duplicated data. Then, the size of our data is 135,742

"""# Understanding Data

Inspection ID, License #, Zip, Latitude, and Longitude  are a series of numbers however
they do not refer to a numerical values. I will not do any calculations with these features.
"""

data["Risk"].unique()
sns.countplot(x=data["Risk"])

data['Risk'].value_counts()

plt.figure(figsize = (8, 6))
sns.set(style = 'dark', palette = 'colorblind', color_codes = True)
ax = sns.countplot(y = 'Results', data = data, color = 'orange')
plt.show()

data["Results"].unique()
sns.countplot(x=data["Results"])

data['Results'].value_counts()

len(data[data["Risk"].isna()])

"""This is an imbalanced dataset. Then I will need to implement balancing starategy before classification.

Let's see what features we might need in our classification model:

Target feature: Risk

Alternative target feature: Results

Independent vairables: 

License #

Facility Type

City

Zip

Inspection Date

Inspection Type

Violations
"""

columns = ["Inspection ID","License #", "Facility Type", "Risk", "City", "Zip", "Inspection Date", "Inspection Type", "Results"
, "Violations"]

for col in columns:
    print(col, ":", data[col].nunique())

"""The Inspection Id and name of the restaurants do

```
# This is formatted as code
```

 not effect the Risk feature. 
State is the same for all restaurants.
I do not need open address, I already include Zipcode for address information.
Lattitude, Longitude, and Location might be useful for plotting maps. 
"""

df = data[columns].copy()
df.head()

"""# Data Preprocessing

There exists multiple violation codes for some restaurants, then I need to seperate the violan codes from this Violation column. The violations are listed in the same column by using '|".
"""

df2 = df.join(df['Violations'].str.split('|',expand = True).add_prefix('Violations_')) 
df2 = df2.drop(columns = {"Violations"})
df2 = df2.melt(id_vars=["Inspection ID","Facility Type","Risk","Results", "Inspection Date","Inspection Type"], 
        var_name="viol", 
        value_name="Violation_id")
df2 = df2.drop(columns = {'viol'})
df2 = df2.dropna(subset = 'Violation_id')
df2['Violation_id'] = (df2['Violation_id'].str.rsplit('.')).str[0]
df2["Violation_id"] = df2["Violation_id"].str.strip()
df2.head(2)

df2.isnull().sum()

df2["Month"] = df2["Inspection Date"].astype(str).str[:2]
df2["Day"] = df2["Inspection Date"].astype(str).str[3:5]
df2["Year"] = df2["Inspection Date"].astype(str).str[-4:]
df2 = df2.drop(columns={"Inspection Date"})
df2

"""# EDA

The composition of all restaurants with respect to the Results category
"""

fig, ax = plt.subplots(figsize=(12,8))
name = df2['Results'].unique()
ax = sns.countplot(x='Results', hue='Risk', data=df2, palette='Set2')
ax.set_title("Results Distribution by Risk", fontsize = 8, weight = 'bold')
ax.set_xticklabels (name, rotation = 45)

totals = []
for i in ax.patches:
    totals.append(i.get_height())
total = sum(totals)
for i in ax.patches:
    ax.text(i.get_x()+.05, i.get_height()-15,
            str(round((i.get_height()/total)*100, 2))+'%', fontsize=8,
                color='black', weight = 'bold')  
plt.tight_layout()

df2.nunique()

risk1 = df2[df2["Risk"]=='Risk 1 (High)']
risk2 = df2[df2["Risk"]=='Risk 2 (Medium)']
risk3 = df2[df2["Risk"]=='Risk 3 (Low)']
plt.subplot()
sns.histplot(risk1["Results"],color='green',alpha=0.5,label='High')
sns.histplot(risk2["Results"],color='blue',alpha=0.5,label='Medium')
sns.histplot(risk3["Results"],color='orange',alpha=0.5,label='Low')
plt.legend()

df2.head()

risk1 = df2[df2["Risk"]=='Risk 1 (High)']
risk2 = df2[df2["Risk"]=='Risk 2 (Medium)']
risk3 = df2[df2["Risk"]=='Risk 3 (Low)']
plt.subplot()
sns.histplot(risk1["Year"],color='green',alpha=0.5,label='High')
sns.histplot(risk2["Year"],color='blue',alpha=0.5,label='Medium')
sns.histplot(risk3["Year"],color='orange',alpha=0.5,label='Low')
plt.legend()

risk1 = df2[df2["Risk"]=='Risk 1 (High)']
risk2 = df2[df2["Risk"]=='Risk 2 (Medium)']
risk3 = df2[df2["Risk"]=='Risk 3 (Low)']
plt.subplot()
sns.histplot(risk1["Month"],color='green',alpha=0.5,label='High')
sns.histplot(risk2["Month"],color='blue',alpha=0.5,label='Medium')
sns.histplot(risk3["Month"],color='orange',alpha=0.5,label='Low')
plt.legend()

risk1 = df2[df2["Risk"]=='Risk 1 (High)']
risk2 = df2[df2["Risk"]=='Risk 2 (Medium)']
risk3 = df2[df2["Risk"]=='Risk 3 (Low)']
plt.subplot()
sns.histplot(risk1["Day"],color='green',alpha=0.5,label='High')
sns.histplot(risk2["Day"],color='blue',alpha=0.5,label='Medium')
sns.histplot(risk3["Day"],color='orange',alpha=0.5,label='Low')
plt.legend()

sns.set(rc={'figure.figsize':(11.7,8.27)})
sns.set(font_scale=0.6)

risk1 = df2[df2["Risk"]=='Risk 1 (High)']
risk2 = df2[df2["Risk"]=='Risk 2 (Medium)']
risk3 = df2[df2["Risk"]=='Risk 3 (Low)']
plt.subplot()
sns.histplot(risk1["Violation_id"],color='green',alpha=0.5,label='High')
sns.histplot(risk2["Violation_id"],color='blue',alpha=0.5,label='Medium')
sns.histplot(risk3["Violation_id"],color='orange',alpha=0.5,label='Low')
plt.legend()

"""# Balance The Data"""

df3 = df2[["Inspection ID","Risk","Violation_id"]]
df3["Violation_id"] = "Violation_" + df3["Violation_id"] 
df3

violation_plot = sns.countplot(data=df3, x='Violation_id')
violation_plot.set_xticklabels(violation_plot.get_xticklabels(), rotation=90)

df3["Violation_id"].value_counts()

df3["Violation_id"].nunique()

sns.countplot(data=df3, x='Risk')
plt.show()

# --The End --



